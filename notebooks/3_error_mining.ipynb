{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de trouver les erreurs les plus fréquentes du parseur afin de corriger le treebank en ayant le plus d'impact possible. Nous regarderons donc quelles sont les types d'erreurs faites par le parseur, quelles sont les plus problématiques et quelle distribution ont ces erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TREEBANK = \"../data/sud_naija-NSC.with_prediction.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le fichier est t-il bien présent ?\n",
    "try:\n",
    "    with open(PATH_TREEBANK, \"r\") as f:\n",
    "        print(\"Le fichier est présent au chemin : {}\".format(PATH_TREEBANK))\n",
    "        pass\n",
    "except FileNotFoundError:\n",
    "    print(\"Le fichier n'est PAS , revoyez le chemin : {}\".format(PATH_TREEBANK))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut commencer à parser le fichier avec la librairie conllup\n",
    "from conllup.conllup import readConlluFile \n",
    "sentences = readConlluFile(PATH_TREEBANK)\n",
    "\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"Le fichier est vide !\")\n",
    "else :\n",
    "    print(\"Le fichier contient {} phrases\".format(len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence de la taille de la phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les nombres de réussite et d'échec pour chaque longueur de phrase\n",
    "results_per_length = {}\n",
    "def get_default_result():\n",
    "    return {\n",
    "            \"total_token\": 0,\n",
    "            \"success_upos\": 0, \n",
    "            \"success_deprel\": 0, \n",
    "            \"success_head\": 0, \n",
    "            \"success_head_and_deprel\": 0, \n",
    "        }\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = sentence[\"treeJson\"][\"nodesJson\"].values()\n",
    "    length = len(tokens)\n",
    "    if length not in results_per_length:\n",
    "        results_per_length[length] = get_default_result()\n",
    "    \n",
    "    for token in tokens:\n",
    "        head_token_ID = str(token['HEAD'])\n",
    "        deprel = token['DEPREL']\n",
    "        upos = token['UPOS']\n",
    "\n",
    "        head_pred = token['MISC']['head_pred']\n",
    "        deprel_pred = token['MISC']['deprel_pred']\n",
    "        upos_pred = token['MISC']['upos_pred']\n",
    "\n",
    "        if head_token_ID == head_pred:\n",
    "            results_per_length[length][\"success_head\"] += 1\n",
    "\n",
    "        if deprel == deprel_pred:\n",
    "            results_per_length[length][\"success_deprel\"] += 1\n",
    "        \n",
    "        if head_token_ID == head_pred and deprel == deprel_pred:\n",
    "            results_per_length[length][\"success_head_and_deprel\"] += 1\n",
    "\n",
    "        if upos == upos_pred:\n",
    "            results_per_length[length][\"success_upos\"] += 1\n",
    "\n",
    "        results_per_length[length][\"total_token\"] += 1\n",
    "\n",
    "# On affiche les résultats\n",
    "import json\n",
    "print(json.dumps(results_per_length, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous utilisons matplotlib pour faire faire nos graphiques\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Voici des paramètres pour que les graphiques soient plus lisibles, changez les à votre convenance\n",
    "params = {\n",
    "   'axes.labelsize': 8,\n",
    " #  'text.fontsize': 8,\n",
    "   'legend.fontsize': 10,\n",
    "   'xtick.labelsize': 10,\n",
    "   'ytick.labelsize': 10,\n",
    "   'text.usetex': False,\n",
    "   'figure.figsize': [10, 5]\n",
    "   }\n",
    "mpl.rcParams.update(params)\n",
    "plt.style.use('seaborn-v0_8-darkgrid') # pour avoir un fond gris quadrillé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essayons de mettre tout ça dans un graphique\n",
    "# On va plotter les ratio d'echec (1 - ratio_reussite) ça sera plus visuel\n",
    "# Dans un même graphique on va plotter les 3 ratios : upos, deprel, head\n",
    "\n",
    "colors = [\"red\", \"green\", \"blue\", \"orange\"]\n",
    "\n",
    "x_lim = [5, 80] # on ne prend pas en compte les phrases de moins de 5 tokens et de plus de 80 tokens\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i, label in enumerate([\"deprel\", \"upos\", \"head\"]):\n",
    "    x = list(range(x_lim[0], x_lim[1]))\n",
    "    y = []\n",
    "    for length in x:\n",
    "        number_success = results_per_length.get(length, get_default_result())[\"success_{}\".format(label)]\n",
    "        number_total = results_per_length.get(length, get_default_result())[\"total_token\"]\n",
    "        \n",
    "        fail_ratio = 0\n",
    "        if number_total != 0:\n",
    "            fail_ratio = (number_total - number_success) / number_total\n",
    "        \n",
    "        y.append(fail_ratio)\n",
    "\n",
    "    plt.plot(range(x_lim[0], x_lim[1]), y, label=label, color=colors[i])\n",
    "\n",
    "    # # si on veut afficher les approximations linéaires :\n",
    "    # from sklearn.linear_model import LinearRegression\n",
    "    # import numpy as np\n",
    "    # regressor = LinearRegression()  \n",
    "    # x = np.array(x).reshape(-1, 1)\n",
    "    # y = np.array(y).reshape(-1, 1)\n",
    "    # regressor.fit(x, y)\n",
    "    # plt.plot(x, regressor.predict(x) ,color=colors[i], linestyle=\"dotted\")\n",
    "\n",
    "plt.xlabel(\"taille de la phrase\")\n",
    "plt.ylabel(\"probabilité d'erreur pour un token\")\n",
    "plt.legend()\n",
    "plt.xlim([x_lim[0]+1,x_lim[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Est-ce que ces résultats étaient attendus ?\n",
    "- À quel(s) biais devons nous faire attention ?\n",
    "\n",
    "NB : Il faudrait utiliser des tests de significativité afin de prouver que les corrélations linéaires ne soient pas dû au hasard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erreurs de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère d'abord les listes des features réelles et prédites\n",
    "gold_uposs = []\n",
    "gold_deprels = []\n",
    "gold_heads = []\n",
    "\n",
    "pred_uposs = []\n",
    "pred_deprels = []\n",
    "pred_heads = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = sentence[\"treeJson\"][\"nodesJson\"].values()\n",
    "    for token in tokens:\n",
    "        gold_uposs.append(token['UPOS'])\n",
    "        gold_deprels.append(token['DEPREL'])\n",
    "        gold_heads.append(token['HEAD'])\n",
    "\n",
    "        pred_uposs.append(token['MISC']['upos_pred'])\n",
    "        pred_deprels.append(token['MISC']['deprel_pred'])\n",
    "        pred_heads.append(token['MISC']['head_pred'])\n",
    "\n",
    "set_uposs = set(gold_uposs)\n",
    "set_deprels = set(gold_deprels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erreurs de POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelles sont les plus grosses confusions de POS ?\n",
    "\n",
    "# On va créer un dictionnaire qui va contenir pour chaque couple de POS, le nombre de fois où on a eu cette confusion\n",
    "confusion_matrix_upos = {}\n",
    "\n",
    "for gold_upos in set_uposs:\n",
    "    confusion_matrix_upos[gold_upos] = {}\n",
    "    for pred_upos in set_uposs:\n",
    "        confusion_matrix_upos[gold_upos][pred_upos] = 0\n",
    "\n",
    "for pred_upos, gold_upos in zip(pred_uposs, gold_uposs):\n",
    "    confusion_matrix_upos[gold_upos][pred_upos] += 1\n",
    "\n",
    "# # On trie le dictionnaire par ordre décroissant de nombre d'erreurs\n",
    "# confusion_matrix_upos = sorted(confusion_matrix_upos.items(), key=lambda x: x[1], reverse=True)\n",
    "# print(json.dumps(confusion_matrix_upos, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
