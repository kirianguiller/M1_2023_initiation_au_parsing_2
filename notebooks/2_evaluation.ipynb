{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Nous allons maintenant évaluer le résultat du parseur et simuler un accord inter-annotateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TREEBANK = \"../data/sud_naija-NSC.with_prediction.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le fichier est t-il bien présent ?\n",
    "try:\n",
    "    with open(PATH_TREEBANK, \"r\") as f:\n",
    "        print(\"Le fichier est présent au chemin : {}\".format(PATH_TREEBANK))\n",
    "        pass\n",
    "except FileNotFoundError:\n",
    "    print(\"Le fichier n'est PAS , revoyez le chemin : {}\".format(PATH_TREEBANK))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut commencer à parser le fichier avec la librairie conllup\n",
    "from conllup.conllup import readConlluFile \n",
    "sentences = readConlluFile(PATH_TREEBANK)\n",
    "\n",
    "if len(sentences) == 0:\n",
    "    raise ValueError(\"Le fichier est vide !\")\n",
    "else :\n",
    "    print(\"Le fichier contient {} phrases\".format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculons le coefficient de Kappa-Cohen pour les catégories syntaxiques\n",
    "from conllup.conllup import readConlluFile\n",
    "\n",
    "# On récupère les catégories syntaxiques\n",
    "gold_UPOS = []\n",
    "pred_UPOS = []\n",
    "for sentence in sentences:\n",
    "    for token in sentence['treeJson']['nodesJson'].values():\n",
    "        gold_UPOS.append(token['UPOS'])\n",
    "        pred_UPOS.append(token['MISC']['upos_pred'])\n",
    "\n",
    "if len(gold_UPOS) != len(pred_UPOS):\n",
    "    raise ValueError(\"Les deux listes ne sont pas de la même taille !\")\n",
    "print(\"Les deux listes sont de la même taille : {} éléments\".format(len(gold_UPOS)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explication du Kappa de Cohen\n",
    "\n",
    "La formule du score de Cohen Kappa est conçue pour mesurer l'accord entre deux évaluateurs en prenant en compte la possibilité d'un accord dû au hasard. Voici la formule :\n",
    "\n",
    "$$\n",
    "\\kappa = \\frac{P - Q}{1 - P}\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- \\(P\\) est la proportion observée d'accord entre les annotateurs.\n",
    "- \\(Q\\) est la proportion d'accord attendue par hasard.\n",
    "\n",
    "Pour calculer ces proportions :\n",
    "\n",
    "1. **Proportion observée d'accord (\\(P\\))** : C'est la proportion de fois où les deux annotateurs sont d'accord. Vous la calculez en comptant le nombre de fois où les deux annotateurs ont donné la même étiquette, puis en divisant ce nombre par le nombre total d'éléments annotés.\n",
    "\n",
    "2. **Proportion d'accord attendue par hasard (\\(Q\\))** : C'est un peu plus compliqué. Pour chaque catégorie d'étiquette, vous calculez la probabilité que les deux annotateurs choisissent cette catégorie par hasard. Cela se fait en calculant la proportion de fois où chaque annotateur a utilisé chaque catégorie, puis en multipliant ces proportions pour chaque catégorie et en les additionnant. Formellement, si vous avez \\( n \\) catégories, et que la proportion de fois où l'annotateur 1 a choisi la catégorie \\( i \\) est \\( p_{1i} \\) et la proportion pour l'annotateur 2 est \\( p_{2i} \\), alors \\( P_e = \\sum_{i=1}^{n} (p_{1i} \\times p_{2i}) \\).\n",
    "\n",
    "\n",
    "Le score de Kappa peut être interprété comme suit :\n",
    "\n",
    "- Un score de 1 indique un accord parfait.\n",
    "- Un score de 0 indique que l'accord est exactement celui attendu par hasard.\n",
    "- Un score négatif indique un désaccord.\n",
    "\n",
    "Cohen Kappa est particulièrement utile car il tient compte de l'accord dû au hasard, ce qui le rend plus robuste que de simplement calculer le pourcentage d'accord direct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule le coefficient de Kappa-Cohen à la main\n",
    "\n",
    "## On calcule la proportion observée d'accord (probabilité d'accord total)\n",
    "\n",
    "number_of_agreements = 0\n",
    "total_number_of_tokens = 0\n",
    "\n",
    "for (gold, pred) in zip(gold_UPOS, pred_UPOS):\n",
    "    if gold == pred:\n",
    "        number_of_agreements += 1\n",
    "    total_number_of_tokens += 1\n",
    "\n",
    "p = number_of_agreements / total_number_of_tokens\n",
    "\n",
    "print(\"La probabilité d'accord par catégorie est de : {}\".format(p))\n",
    "\n",
    "## maintenant, on calcule la proportion attendue d'accord (probabilité d'accord par chance) Q\n",
    "number_of_category = 0\n",
    "\n",
    "sum_of_products = 0\n",
    "for category in set(gold_UPOS):\n",
    "    probability_in_gold = gold_UPOS.count(category) / len(gold_UPOS)\n",
    "    probability_in_pred = pred_UPOS.count(category) / len(pred_UPOS)\n",
    "    sum_of_products += probability_in_gold * probability_in_pred\n",
    "    number_of_category += 1\n",
    "\n",
    "q = sum_of_products / number_of_category\n",
    "print(\"La probabilité d'accord par chance (par categorie) est de : {}\".format(q))\n",
    "\n",
    "# On calcule le coefficient de Kappa-Cohen\n",
    "k_upos = (p - q) / (1 - q)\n",
    "print(\"Le coefficient de Kappa-Cohen est de : {}\".format(k_upos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faisons une fonction de ce code\n",
    "\n",
    "def kappa_cohen(gold_cat, pred_cat):\n",
    "    \"\"\" \n",
    "    Calcule le coefficient de Kappa-Cohen pour deux listes de valeurs \n",
    "    \"\"\"     \n",
    "    number_of_agreements = 0\n",
    "    total_number_of_tokens = 0\n",
    "\n",
    "    for (gold, pred) in zip(gold_cat, pred_cat):\n",
    "        if gold == pred:\n",
    "            number_of_agreements += 1\n",
    "        total_number_of_tokens += 1\n",
    "\n",
    "    p = number_of_agreements / total_number_of_tokens\n",
    "\n",
    "    print(\"La probabilité d'accord par catégorie est de : {}\".format(p))\n",
    "\n",
    "    ## maintenant, on calcule la proportion attendue d'accord (probabilité d'accord par chance) Q\n",
    "    number_of_category = 0\n",
    "\n",
    "    sum_of_products = 0\n",
    "    for category in set(gold_cat):\n",
    "        probability_in_gold = gold_cat.count(category) / len(gold_cat)\n",
    "        probability_in_pred = pred_cat.count(category) / len(pred_cat)\n",
    "        sum_of_products += probability_in_gold * probability_in_pred\n",
    "        number_of_category += 1\n",
    "\n",
    "    q = sum_of_products / number_of_category\n",
    "    print(\"La probabilité d'accord par chance (par categorie) est de : {}\".format(q))\n",
    "\n",
    "    # On calcule le coefficient de Kappa-Cohen\n",
    "    k = (p - q) / (1 - q)\n",
    "    print(\"Le coefficient de Kappa-Cohen est de : {}\".format(k))\n",
    "    return k\n",
    "\n",
    "# On vérifie que la fonction donne bien le même résultat que le code précédent\n",
    "assert kappa_cohen(gold_UPOS, pred_UPOS) == k_upos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faisons donc de même pour les catégories de dépendances\n",
    "gold_DEPREL = []\n",
    "pred_DEPREL = []\n",
    "for sentence in sentences:\n",
    "    for token in sentence['treeJson']['nodesJson'].values():\n",
    "        gold_DEPREL.append(token['DEPREL'])\n",
    "        pred_DEPREL.append(token['MISC']['deprel_pred'])\n",
    "\n",
    "if len(gold_DEPREL) != len(pred_DEPREL):\n",
    "    raise ValueError(\"Les deux listes ne sont pas de la même taille !\")\n",
    "print(\"Les deux listes sont de la même taille : {} éléments\".format(len(gold_DEPREL)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule le coefficient de Kappa-Cohen\n",
    "k_deprel = kappa_cohen(gold_DEPREL, pred_DEPREL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'étiquette de relation syntaxique semble plus compliquée à prédire que l'étiquette de catégorie du discours.\n",
    "\n",
    "NB : On ne peut pas appliquer ce coefficient Kappa-Cohen à la prédiction des gouverneur puisque cette prédiction n'est pas un problème de classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculons maintenant les trois scores LAS, UAS et LAS\n",
    "# On commence par calculer le nombre de tokens correctement étiquetés\n",
    "correctly_labeled_tokens = 0\n",
    "correctly_attached_tokens = 0\n",
    "correctly_labeled_and_attached_tokens = 0\n",
    "correct_UPOSs = 0\n",
    "total_number_of_tokens = 0\n",
    "\n",
    "for sentence in sentences:\n",
    "    for token in sentence['treeJson']['nodesJson'].values():\n",
    "        head_token_ID = str(token['HEAD'])\n",
    "        deprel = token['DEPREL']\n",
    "        upos = token['UPOS']\n",
    "\n",
    "        head_pred = token['MISC']['head_pred']\n",
    "        deprel_pred = token['MISC']['deprel_pred']\n",
    "        upos_pred = token['MISC']['upos_pred']\n",
    "\n",
    "        if head_token_ID == head_pred:\n",
    "            correctly_attached_tokens += 1\n",
    "\n",
    "        if deprel == deprel_pred:\n",
    "            correctly_labeled_tokens += 1\n",
    "        \n",
    "        if head_token_ID == head_pred and deprel == deprel_pred:\n",
    "            correctly_labeled_and_attached_tokens += 1\n",
    "\n",
    "        if upos == upos_pred:\n",
    "            correct_UPOSs += 1\n",
    "\n",
    "        total_number_of_tokens += 1\n",
    "\n",
    "LAS = correctly_labeled_and_attached_tokens / total_number_of_tokens\n",
    "LUS = correctly_labeled_tokens / total_number_of_tokens\n",
    "UAS = correctly_attached_tokens / total_number_of_tokens\n",
    "UPOS = correct_UPOSs / total_number_of_tokens\n",
    "\n",
    "print(\"Le score LAS est de : {}\".format(LAS))\n",
    "print(\"Le score LUS est de : {}\".format(LUS))\n",
    "print(\"Le score UAS est de : {}\".format(UAS))\n",
    "print(\"Le score UPOS est de : {}\".format(UPOS))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combien de phrases ont au moins un token mal étiqueté (pour chaque caractéristique) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il faudrait maintenant que nous recalculions toutes ces mesures sans les ponctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
